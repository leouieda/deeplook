{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox\n",
    "\n",
    "Experimenting with implementations of a functional API for inverse problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "\n",
    "* Hidding things from the user inside classes makes the library more accessible but the code more complex and obscure.\n",
    "* Maybe go back to a more explicit API where the user needs to know that an optimization method is being used and which one. \n",
    "* The bad thing about that is that the code itself doesn't have all the instruction for executing an inversion (just the Jacobian and predicted data probably).\n",
    "* Can get around this by investing in examples in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask as da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "Functions that optimize a goal function. \n",
    "\n",
    "Gradient methods need to be able to calculate the function and its gradient and Hessian matrices. \n",
    "\n",
    "Should be separate functions or single function that takes an argument specifying what it wants? Argument in favor of single function is that gradient and Hessian ofter share expensive variables (like Jacobian).\n",
    "\n",
    "Include stopping criterion or just run for given number of iterations? Usually iterations are expensive so maybe running one at a time and looking at intermediate results is a good thing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levmarq(function, initial, iterations, step=2, step_increase=2,\n",
    "            maxsteps=10, precondition=True):\n",
    "    p = initial\n",
    "    lamb = step\n",
    "    previous_value = functions(p)\n",
    "    for iteration in range(iterations):\n",
    "        grad, hess = function(p, calculate=['gradient', 'hessian'])\n",
    "        deltap = np.linalg.solve(hess, -grad)\n",
    "        p = p + deltap\n",
    "        value = function(p)\n",
    "        if value > previous_value:\n",
    "            print(\"Function increased\")\n",
    "            break\n",
    "        previous_value = value\n",
    "    return p\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
